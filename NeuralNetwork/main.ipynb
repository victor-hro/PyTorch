{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "c19c032799aded710ddcd6697003cf51bf230c726afa9047e4722979936d7246"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY4Ro67P1bwU"
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW1BZ6np1bwj",
        "outputId": "63d22fb8-da0b-43f2-d0c1-ffed258bac2d"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7X7WHh1bwz"
      },
      "source": [
        "args = {\n",
        "    \"batch_size\": 20,\n",
        "    \"num_workers\": 2,\n",
        "    \"num_classes\": 10,\n",
        "    \"lr\": 1e-4,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200\n",
        "}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxzY1KNN277R"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv\n",
        "\n",
        "- instant: record index\n",
        "- dteday : date\n",
        "- season : season (1:winter, 2:spring, 3:summer, 4:fall)\n",
        "- yr : year (0: 2011, 1:2012)\n",
        "- mnth : month ( 1 to 12)\n",
        "- hr : hour (0 to 23)\n",
        "- holiday : weather day is holiday or not (extracted from [Web Link])\n",
        "- weekday : day of the week\n",
        "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
        "+ weathersit :\n",
        "- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
        "- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
        "- hum: Normalized humidity. The values are divided to 100 (max)\n",
        "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
        "- casual: count of casual users\n",
        "- registered: count of registered users\n",
        "- cnt: count of total rental bikes including both casual and registered\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmwUAD8d2md5",
        "outputId": "64ee4627-54dc-4055-f671-11ba6f4b2484"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
        "!unzip Bike-Sharing-Dataset.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 02:37:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 279992 (273K) [application/x-httpd-php]\n",
            "Saving to: ‘Bike-Sharing-Dataset.zip.1’\n",
            "\n",
            "Bike-Sharing-Datase 100%[===================>] 273.43K   424KB/s    in 0.6s    \n",
            "\n",
            "2021-11-30 02:37:04 (424 KB/s) - ‘Bike-Sharing-Dataset.zip.1’ saved [279992/279992]\n",
            "\n",
            "Archive:  Bike-Sharing-Dataset.zip\n",
            "replace Readme.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: Readme.txt              \n",
            "replace day.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: day.csv                 \n",
            "replace hour.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: hour.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUGFe45x3BBY",
        "outputId": "73ce656e-4545-40c1-a169-d8a04e81c92a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bike-Sharing-Dataset.zip    day.csv   Readme.txt\n",
            "Bike-Sharing-Dataset.zip.1  hour.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FKYJpHa3ECk"
      },
      "source": [
        "# DataViz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "X3PXJHQ81gzF",
        "outputId": "f6e61608-571e-4e18-a3ed-51455a209537"
      },
      "source": [
        "df = pd.read_csv('hour.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17379, 17)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnQzCYhS3Zlf"
      },
      "source": [
        "# Dataset split\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.randperm.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGqziS5o3Uog",
        "outputId": "8c07bff9-2fb4-4793-e219-af92c12b8d57"
      },
      "source": [
        "torch.manual_seed(10)\n",
        "\n",
        "# train set = 80%\n",
        "train_size = int(0.8 * df.shape[0])\n",
        "\n",
        "# random rows\n",
        "idx = torch.randperm(df.shape[0]).tolist()\n",
        "\n",
        "df_train = df.iloc[idx[:train_size]]\n",
        "df_test = df.iloc[idx[train_size:]]\n",
        "\n",
        "print('train samples: {}, test samples: {}'.format(df_train.shape[0], df_test.shape[0]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples: 13903, test samples: 3476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcc2GDaH3o7Q"
      },
      "source": [
        "df_train.to_csv('bike_train.csv', index=False)\n",
        "df_test.to_csv('bike_test.csv', index=False)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grcrCFT84wsr"
      },
      "source": [
        "# Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GKHG6n845V4"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, csv_path:str):\n",
        "        \n",
        "        self.data = pd.read_csv(csv_path).to_numpy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # only 2:14 columns\n",
        "        sample = self.data[idx][2:14]\n",
        "        label = self.data[idx][-1:]\n",
        "\n",
        "        # convert to tensor\n",
        "        sample = torch.from_numpy(sample.astype(np.float32))\n",
        "        label = torch.from_numpy(label.astype(np.float32))\n",
        "        \n",
        "        return sample, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAXMHS7y6ZI0",
        "outputId": "1b0f0c4d-db2d-40cb-ff0c-dcf627dd31b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TEST CELL\n",
        "train_set = MyDataset('bike_train.csv')\n",
        "test_set = MyDataset('bike_test.csv')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=args['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=args['num_workers']\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=args['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=args['num_workers']\n",
        ")\n",
        "\n",
        "for data, label in train_loader:\n",
        "    print('data: {}\\nlabel: {}'.format(data.size(), label.size()))\n",
        "    break"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: torch.Size([20, 12])\n",
            "label: torch.Size([20, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4xsCkXD8h4J"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyK4kA-t6oqo"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.output = nn.Linear(hidden_size, out_size)\n",
        "        # self.softmax = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        feature = self.features(X)\n",
        "        output = self.output(feature)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgIogqAe8lqA"
      },
      "source": [
        "net_params = {\n",
        "    'input_size': len(train_set[0][0]),  # number of features\n",
        "    'hidden_size': 128,\n",
        "    'out_size': 1\n",
        "}\n",
        "\n",
        "model = MLP(**net_params).to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7ztPAiz_nDx"
      },
      "source": [
        "# Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYzsKy5I_i_G"
      },
      "source": [
        "criterion = nn.L1Loss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHucaFSQ_7_f"
      },
      "source": [
        "def train(model, dataloader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for data_, label_ in dataloader:\n",
        "        data, label = data_.to(device), label_.to(device)\n",
        "\n",
        "        # forward\n",
        "        pred = model(data)\n",
        "        loss = criterion(pred, label)\n",
        "        epoch_loss.append(loss.cpu().data)\n",
        "\n",
        "        # barckward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.asarray(epoch_loss)\n",
        "    print('loss: %3f +/- %3f' % (epoch_loss.mean(), epoch_loss.std()))\n",
        "\n",
        "    return epoch_loss.mean()\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA2jgY9NsGNB"
      },
      "source": [
        "def validate(model, dataloader, criterion, optimizer):\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data_, label_ in dataloader:\n",
        "            data, label = data_.to(device), label_.to(device)\n",
        "\n",
        "            # forward\n",
        "            pred = model(data)\n",
        "            loss = criterion(pred, label)\n",
        "            epoch_loss.append(loss.cpu().data)\n",
        "\n",
        "\n",
        "    epoch_loss = np.asarray(epoch_loss)\n",
        "    print('val_loss: %3f +/- %3f' % (epoch_loss.mean(), epoch_loss.std()))\n",
        "\n",
        "    return epoch_loss.mean()\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiR-_e53BaHK",
        "outputId": "87846dfc-65bf-4c22-f9c9-14c7b7939093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for c in range(args['num_epochs']):\n",
        "    print('epoch {}/{}'.format(c, args['num_epochs']))\n",
        "    train(model,train_loader, criterion, optimizer )\n",
        "    validate(model, test_loader, criterion, optimizer)\n",
        "    print('')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0/200\n",
            "loss: 151.504868 +/- 39.518181\n",
            "val_loss: 137.265900 +/- 22.671459\n",
            "\n",
            "epoch 1/200\n",
            "loss: 126.839409 +/- 30.257511\n",
            "val_loss: 117.843552 +/- 28.354454\n",
            "\n",
            "epoch 2/200\n",
            "loss: 121.066429 +/- 27.475492\n",
            "val_loss: 118.355309 +/- 31.488829\n",
            "\n",
            "epoch 3/200\n",
            "loss: 121.581490 +/- 30.689171\n",
            "val_loss: 122.218185 +/- 24.818104\n",
            "\n",
            "epoch 4/200\n",
            "loss: 118.986191 +/- 30.199825\n",
            "val_loss: 114.549835 +/- 27.208967\n",
            "\n",
            "epoch 5/200\n",
            "loss: 111.948814 +/- 26.635614\n",
            "val_loss: 104.134766 +/- 28.183365\n",
            "\n",
            "epoch 6/200\n",
            "loss: 107.556610 +/- 27.700117\n",
            "val_loss: 102.131462 +/- 21.178625\n",
            "\n",
            "epoch 7/200\n",
            "loss: 101.227699 +/- 28.353651\n",
            "val_loss: 98.621193 +/- 18.836142\n",
            "\n",
            "epoch 8/200\n",
            "loss: 99.544022 +/- 26.963415\n",
            "val_loss: 94.738632 +/- 22.511551\n",
            "\n",
            "epoch 9/200\n",
            "loss: 97.539085 +/- 25.615107\n",
            "val_loss: 90.558357 +/- 21.686594\n",
            "\n",
            "epoch 10/200\n",
            "loss: 96.111061 +/- 23.545460\n",
            "val_loss: 88.323090 +/- 24.758808\n",
            "\n",
            "epoch 11/200\n",
            "loss: 94.374260 +/- 23.564030\n",
            "val_loss: 96.402344 +/- 27.724279\n",
            "\n",
            "epoch 12/200\n",
            "loss: 93.306778 +/- 24.994318\n",
            "val_loss: 86.549309 +/- 25.091801\n",
            "\n",
            "epoch 13/200\n",
            "loss: 92.647026 +/- 24.772757\n",
            "val_loss: 95.524277 +/- 21.184048\n",
            "\n",
            "epoch 14/200\n",
            "loss: 92.938087 +/- 23.656311\n",
            "val_loss: 87.194550 +/- 25.674665\n",
            "\n",
            "epoch 15/200\n",
            "loss: 88.935005 +/- 21.876608\n",
            "val_loss: 85.138718 +/- 24.306950\n",
            "\n",
            "epoch 16/200\n",
            "loss: 87.467316 +/- 24.521847\n",
            "val_loss: 84.505104 +/- 19.778297\n",
            "\n",
            "epoch 17/200\n",
            "loss: 85.047737 +/- 22.726742\n",
            "val_loss: 80.441956 +/- 18.332611\n",
            "\n",
            "epoch 18/200\n",
            "loss: 84.535767 +/- 22.709663\n",
            "val_loss: 83.218208 +/- 24.138950\n",
            "\n",
            "epoch 19/200\n",
            "loss: 83.412605 +/- 22.407799\n",
            "val_loss: 79.122528 +/- 22.530916\n",
            "\n",
            "epoch 20/200\n",
            "loss: 83.382851 +/- 22.217751\n",
            "val_loss: 83.069473 +/- 17.253435\n",
            "\n",
            "epoch 21/200\n",
            "loss: 83.203430 +/- 23.447517\n",
            "val_loss: 78.647789 +/- 22.557936\n",
            "\n",
            "epoch 22/200\n",
            "loss: 81.245682 +/- 21.711079\n",
            "val_loss: 83.175087 +/- 20.137304\n",
            "\n",
            "epoch 23/200\n",
            "loss: 82.268990 +/- 20.482685\n",
            "val_loss: 76.531631 +/- 20.778561\n",
            "\n",
            "epoch 24/200\n",
            "loss: 81.516937 +/- 23.307802\n",
            "val_loss: 77.719513 +/- 21.125881\n",
            "\n",
            "epoch 25/200\n",
            "loss: 81.126457 +/- 21.776224\n",
            "val_loss: 81.988037 +/- 25.103739\n",
            "\n",
            "epoch 26/200\n",
            "loss: 80.341995 +/- 22.052681\n",
            "val_loss: 74.737221 +/- 18.524281\n",
            "\n",
            "epoch 27/200\n",
            "loss: 78.621445 +/- 22.459784\n",
            "val_loss: 75.684212 +/- 21.115269\n",
            "\n",
            "epoch 28/200\n",
            "loss: 77.792992 +/- 22.052761\n",
            "val_loss: 76.994789 +/- 22.477850\n",
            "\n",
            "epoch 29/200\n",
            "loss: 76.766251 +/- 22.043530\n",
            "val_loss: 74.393425 +/- 19.300501\n",
            "\n",
            "epoch 30/200\n",
            "loss: 76.121307 +/- 21.383131\n",
            "val_loss: 72.523109 +/- 20.840628\n",
            "\n",
            "epoch 31/200\n",
            "loss: 75.489487 +/- 22.467491\n",
            "val_loss: 72.751831 +/- 20.165630\n",
            "\n",
            "epoch 32/200\n",
            "loss: 74.840790 +/- 20.442373\n",
            "val_loss: 71.507889 +/- 18.719614\n",
            "\n",
            "epoch 33/200\n",
            "loss: 74.709984 +/- 21.100859\n",
            "val_loss: 70.968391 +/- 21.995481\n",
            "\n",
            "epoch 34/200\n",
            "loss: 74.894928 +/- 20.898090\n",
            "val_loss: 72.830223 +/- 22.000433\n",
            "\n",
            "epoch 35/200\n",
            "loss: 74.690376 +/- 22.442719\n",
            "val_loss: 76.042351 +/- 22.266232\n",
            "\n",
            "epoch 36/200\n",
            "loss: 75.245316 +/- 21.435509\n",
            "val_loss: 70.058571 +/- 17.882389\n",
            "\n",
            "epoch 37/200\n",
            "loss: 74.341034 +/- 21.516064\n",
            "val_loss: 74.224045 +/- 17.980398\n",
            "\n",
            "epoch 38/200\n",
            "loss: 73.888206 +/- 20.861694\n",
            "val_loss: 68.912155 +/- 19.536915\n",
            "\n",
            "epoch 39/200\n",
            "loss: 73.648621 +/- 19.983297\n",
            "val_loss: 74.125305 +/- 23.453333\n",
            "\n",
            "epoch 40/200\n",
            "loss: 74.481453 +/- 21.494822\n",
            "val_loss: 71.738739 +/- 17.345184\n",
            "\n",
            "epoch 41/200\n",
            "loss: 72.580025 +/- 21.403082\n",
            "val_loss: 67.543823 +/- 17.295889\n",
            "\n",
            "epoch 42/200\n",
            "loss: 72.107895 +/- 19.947683\n",
            "val_loss: 73.458199 +/- 22.473372\n",
            "\n",
            "epoch 43/200\n",
            "loss: 71.921494 +/- 20.856150\n",
            "val_loss: 68.555878 +/- 21.158348\n",
            "\n",
            "epoch 44/200\n",
            "loss: 70.893524 +/- 20.526937\n",
            "val_loss: 68.124313 +/- 18.135668\n",
            "\n",
            "epoch 45/200\n",
            "loss: 72.205193 +/- 20.081057\n",
            "val_loss: 70.998741 +/- 21.790209\n",
            "\n",
            "epoch 46/200\n",
            "loss: 70.561646 +/- 20.448589\n",
            "val_loss: 66.063774 +/- 18.912554\n",
            "\n",
            "epoch 47/200\n",
            "loss: 70.903755 +/- 21.727304\n",
            "val_loss: 69.724113 +/- 18.156569\n",
            "\n",
            "epoch 48/200\n",
            "loss: 72.038437 +/- 21.354713\n",
            "val_loss: 71.081779 +/- 20.807722\n",
            "\n",
            "epoch 49/200\n",
            "loss: 70.306206 +/- 20.990440\n",
            "val_loss: 65.628326 +/- 18.416962\n",
            "\n",
            "epoch 50/200\n",
            "loss: 70.708984 +/- 21.225231\n",
            "val_loss: 68.806137 +/- 17.413868\n",
            "\n",
            "epoch 51/200\n",
            "loss: 71.022293 +/- 21.561697\n",
            "val_loss: 70.782661 +/- 19.825855\n",
            "\n",
            "epoch 52/200\n",
            "loss: 70.677025 +/- 19.567616\n",
            "val_loss: 65.804283 +/- 18.451191\n",
            "\n",
            "epoch 53/200\n",
            "loss: 69.795593 +/- 20.732819\n",
            "val_loss: 65.216751 +/- 17.155949\n",
            "\n",
            "epoch 54/200\n",
            "loss: 69.900986 +/- 20.377684\n",
            "val_loss: 69.363129 +/- 20.921400\n",
            "\n",
            "epoch 55/200\n",
            "loss: 70.459793 +/- 20.655001\n",
            "val_loss: 70.137909 +/- 18.291183\n",
            "\n",
            "epoch 56/200\n",
            "loss: 69.926620 +/- 21.062988\n",
            "val_loss: 68.587837 +/- 19.430473\n",
            "\n",
            "epoch 57/200\n",
            "loss: 69.760735 +/- 18.911518\n",
            "val_loss: 64.937805 +/- 18.423500\n",
            "\n",
            "epoch 58/200\n",
            "loss: 69.149002 +/- 21.343790\n",
            "val_loss: 64.262108 +/- 16.865641\n",
            "\n",
            "epoch 59/200\n",
            "loss: 68.961548 +/- 18.810867\n",
            "val_loss: 67.699867 +/- 18.956137\n",
            "\n",
            "epoch 60/200\n",
            "loss: 69.603920 +/- 20.653027\n",
            "val_loss: 68.381218 +/- 16.992205\n",
            "\n",
            "epoch 61/200\n",
            "loss: 69.256210 +/- 21.225634\n",
            "val_loss: 67.680374 +/- 20.591526\n",
            "\n",
            "epoch 62/200\n",
            "loss: 67.751488 +/- 19.299635\n",
            "val_loss: 64.254333 +/- 17.760185\n",
            "\n",
            "epoch 63/200\n",
            "loss: 66.497185 +/- 19.405228\n",
            "val_loss: 63.792114 +/- 18.073784\n",
            "\n",
            "epoch 64/200\n",
            "loss: 66.748100 +/- 20.020767\n",
            "val_loss: 65.915497 +/- 19.688856\n",
            "\n",
            "epoch 65/200\n",
            "loss: 66.218201 +/- 19.509155\n",
            "val_loss: 65.098473 +/- 15.645344\n",
            "\n",
            "epoch 66/200\n",
            "loss: 66.001381 +/- 18.494617\n",
            "val_loss: 62.789993 +/- 18.786465\n",
            "\n",
            "epoch 67/200\n",
            "loss: 66.457085 +/- 20.661951\n",
            "val_loss: 65.447678 +/- 19.700344\n",
            "\n",
            "epoch 68/200\n",
            "loss: 65.114861 +/- 18.255806\n",
            "val_loss: 62.492065 +/- 17.760675\n",
            "\n",
            "epoch 69/200\n",
            "loss: 65.262192 +/- 18.597784\n",
            "val_loss: 63.436634 +/- 17.718922\n",
            "\n",
            "epoch 70/200\n",
            "loss: 65.272987 +/- 20.175558\n",
            "val_loss: 62.592999 +/- 18.136114\n",
            "\n",
            "epoch 71/200\n",
            "loss: 64.608238 +/- 18.719202\n",
            "val_loss: 63.846085 +/- 19.126858\n",
            "\n",
            "epoch 72/200\n",
            "loss: 64.189018 +/- 18.772028\n",
            "val_loss: 62.297123 +/- 16.121096\n",
            "\n",
            "epoch 73/200\n",
            "loss: 64.117676 +/- 19.658878\n",
            "val_loss: 62.642994 +/- 17.435764\n",
            "\n",
            "epoch 74/200\n",
            "loss: 63.903252 +/- 18.725006\n",
            "val_loss: 60.969711 +/- 19.464861\n",
            "\n",
            "epoch 75/200\n",
            "loss: 63.507458 +/- 18.626560\n",
            "val_loss: 62.496452 +/- 17.506790\n",
            "\n",
            "epoch 76/200\n",
            "loss: 62.763901 +/- 18.820124\n",
            "val_loss: 61.027340 +/- 17.399109\n",
            "\n",
            "epoch 77/200\n",
            "loss: 63.441715 +/- 18.296251\n",
            "val_loss: 61.125595 +/- 16.448093\n",
            "\n",
            "epoch 78/200\n",
            "loss: 62.338497 +/- 18.439510\n",
            "val_loss: 60.888954 +/- 17.098555\n",
            "\n",
            "epoch 79/200\n",
            "loss: 61.715889 +/- 18.033794\n",
            "val_loss: 59.927029 +/- 16.011930\n",
            "\n",
            "epoch 80/200\n",
            "loss: 61.168148 +/- 17.893505\n",
            "val_loss: 60.013683 +/- 17.058260\n",
            "\n",
            "epoch 81/200\n",
            "loss: 61.092140 +/- 17.494959\n",
            "val_loss: 60.082535 +/- 16.605255\n",
            "\n",
            "epoch 82/200\n",
            "loss: 60.980537 +/- 18.136045\n",
            "val_loss: 59.764889 +/- 17.787760\n",
            "\n",
            "epoch 83/200\n",
            "loss: 60.729408 +/- 17.832125\n",
            "val_loss: 61.135921 +/- 17.714447\n",
            "\n",
            "epoch 84/200\n",
            "loss: 60.788372 +/- 17.215481\n",
            "val_loss: 60.135864 +/- 16.040039\n",
            "\n",
            "epoch 85/200\n",
            "loss: 60.550259 +/- 17.580986\n",
            "val_loss: 60.069267 +/- 18.738993\n",
            "\n",
            "epoch 86/200\n",
            "loss: 60.655964 +/- 17.032730\n",
            "val_loss: 60.094879 +/- 16.073011\n",
            "\n",
            "epoch 87/200\n",
            "loss: 60.862576 +/- 18.481916\n",
            "val_loss: 59.350101 +/- 17.079489\n",
            "\n",
            "epoch 88/200\n",
            "loss: 60.236248 +/- 17.151058\n",
            "val_loss: 59.762157 +/- 17.298492\n",
            "\n",
            "epoch 89/200\n",
            "loss: 60.210903 +/- 17.893841\n",
            "val_loss: 59.912792 +/- 17.902788\n",
            "\n",
            "epoch 90/200\n",
            "loss: 60.034157 +/- 16.762154\n",
            "val_loss: 59.756744 +/- 16.014374\n",
            "\n",
            "epoch 91/200\n",
            "loss: 59.977337 +/- 16.556784\n",
            "val_loss: 59.384182 +/- 15.100360\n",
            "\n",
            "epoch 92/200\n",
            "loss: 60.011505 +/- 16.415279\n",
            "val_loss: 59.343727 +/- 16.179979\n",
            "\n",
            "epoch 93/200\n",
            "loss: 59.360947 +/- 16.155958\n",
            "val_loss: 59.115112 +/- 15.037729\n",
            "\n",
            "epoch 94/200\n",
            "loss: 59.465000 +/- 16.293171\n",
            "val_loss: 58.662525 +/- 16.209705\n",
            "\n",
            "epoch 95/200\n",
            "loss: 58.979740 +/- 17.194427\n",
            "val_loss: 58.499603 +/- 18.146261\n",
            "\n",
            "epoch 96/200\n",
            "loss: 58.889996 +/- 16.522684\n",
            "val_loss: 59.229527 +/- 16.085175\n",
            "\n",
            "epoch 97/200\n",
            "loss: 58.702114 +/- 17.151527\n",
            "val_loss: 57.946857 +/- 16.366629\n",
            "\n",
            "epoch 98/200\n",
            "loss: 58.032143 +/- 16.488472\n",
            "val_loss: 57.872913 +/- 16.459978\n",
            "\n",
            "epoch 99/200\n",
            "loss: 57.834152 +/- 16.883224\n",
            "val_loss: 57.493153 +/- 15.690529\n",
            "\n",
            "epoch 100/200\n",
            "loss: 58.283081 +/- 16.889021\n",
            "val_loss: 57.642151 +/- 15.193824\n",
            "\n",
            "epoch 101/200\n",
            "loss: 58.029633 +/- 17.132343\n",
            "val_loss: 57.060238 +/- 13.077365\n",
            "\n",
            "epoch 102/200\n",
            "loss: 58.643398 +/- 16.358938\n",
            "val_loss: 58.450645 +/- 16.661688\n",
            "\n",
            "epoch 103/200\n",
            "loss: 58.175838 +/- 16.799532\n",
            "val_loss: 59.170830 +/- 16.240433\n",
            "\n",
            "epoch 104/200\n",
            "loss: 58.132755 +/- 16.980101\n",
            "val_loss: 57.505074 +/- 16.012333\n",
            "\n",
            "epoch 105/200\n",
            "loss: 58.077652 +/- 16.167770\n",
            "val_loss: 58.171688 +/- 14.363571\n",
            "\n",
            "epoch 106/200\n",
            "loss: 58.358360 +/- 16.812143\n",
            "val_loss: 60.418575 +/- 18.458420\n",
            "\n",
            "epoch 107/200\n",
            "loss: 58.386490 +/- 17.570728\n",
            "val_loss: 57.933388 +/- 15.537865\n",
            "\n",
            "epoch 108/200\n",
            "loss: 58.244736 +/- 17.557055\n",
            "val_loss: 58.855995 +/- 14.621677\n",
            "\n",
            "epoch 109/200\n",
            "loss: 57.289288 +/- 16.451746\n",
            "val_loss: 57.897804 +/- 14.655051\n",
            "\n",
            "epoch 110/200\n",
            "loss: 58.258514 +/- 16.800114\n",
            "val_loss: 58.853874 +/- 18.106825\n",
            "\n",
            "epoch 111/200\n",
            "loss: 57.076889 +/- 16.197985\n",
            "val_loss: 59.179424 +/- 16.545406\n",
            "\n",
            "epoch 112/200\n",
            "loss: 57.413929 +/- 16.608864\n",
            "val_loss: 57.555923 +/- 14.595029\n",
            "\n",
            "epoch 113/200\n",
            "loss: 57.387554 +/- 17.224602\n",
            "val_loss: 59.263351 +/- 14.446993\n",
            "\n",
            "epoch 114/200\n",
            "loss: 57.818386 +/- 16.068953\n",
            "val_loss: 57.997692 +/- 16.394163\n",
            "\n",
            "epoch 115/200\n",
            "loss: 57.139599 +/- 16.400860\n",
            "val_loss: 59.148762 +/- 17.550043\n",
            "\n",
            "epoch 116/200\n",
            "loss: 57.768593 +/- 16.778427\n",
            "val_loss: 57.467701 +/- 15.279632\n",
            "\n",
            "epoch 117/200\n",
            "loss: 57.749035 +/- 16.732489\n",
            "val_loss: 57.556488 +/- 15.421098\n",
            "\n",
            "epoch 118/200\n",
            "loss: 57.468361 +/- 16.443077\n",
            "val_loss: 59.287323 +/- 17.430574\n",
            "\n",
            "epoch 119/200\n",
            "loss: 57.414066 +/- 15.893312\n",
            "val_loss: 57.476898 +/- 15.345289\n",
            "\n",
            "epoch 120/200\n",
            "loss: 56.814968 +/- 16.062300\n",
            "val_loss: 58.662670 +/- 16.092197\n",
            "\n",
            "epoch 121/200\n",
            "loss: 57.647472 +/- 16.465235\n",
            "val_loss: 57.644268 +/- 14.985396\n",
            "\n",
            "epoch 122/200\n",
            "loss: 56.500580 +/- 16.502617\n",
            "val_loss: 56.890110 +/- 17.144846\n",
            "\n",
            "epoch 123/200\n",
            "loss: 57.267414 +/- 16.266388\n",
            "val_loss: 57.894642 +/- 15.304749\n",
            "\n",
            "epoch 124/200\n",
            "loss: 57.009480 +/- 17.082184\n",
            "val_loss: 56.690784 +/- 16.422171\n",
            "\n",
            "epoch 125/200\n",
            "loss: 57.290276 +/- 16.256683\n",
            "val_loss: 58.210140 +/- 17.968376\n",
            "\n",
            "epoch 126/200\n",
            "loss: 57.332771 +/- 17.450026\n",
            "val_loss: 57.983044 +/- 13.964697\n",
            "\n",
            "epoch 127/200\n",
            "loss: 57.616188 +/- 16.453423\n",
            "val_loss: 56.671616 +/- 14.914143\n",
            "\n",
            "epoch 128/200\n",
            "loss: 57.118713 +/- 16.746258\n",
            "val_loss: 56.960140 +/- 15.696817\n",
            "\n",
            "epoch 129/200\n",
            "loss: 57.167671 +/- 16.274811\n",
            "val_loss: 56.946278 +/- 16.041079\n",
            "\n",
            "epoch 130/200\n",
            "loss: 56.971516 +/- 17.068789\n",
            "val_loss: 56.331898 +/- 16.021193\n",
            "\n",
            "epoch 131/200\n",
            "loss: 56.690216 +/- 15.400166\n",
            "val_loss: 56.906479 +/- 16.245916\n",
            "\n",
            "epoch 132/200\n",
            "loss: 56.733612 +/- 16.075096\n",
            "val_loss: 56.219177 +/- 16.690619\n",
            "\n",
            "epoch 133/200\n",
            "loss: 56.215698 +/- 15.714133\n",
            "val_loss: 56.541828 +/- 14.476192\n",
            "\n",
            "epoch 134/200\n",
            "loss: 56.401073 +/- 15.387544\n",
            "val_loss: 57.017498 +/- 15.485165\n",
            "\n",
            "epoch 135/200\n",
            "loss: 55.740925 +/- 15.705360\n",
            "val_loss: 56.367165 +/- 15.256645\n",
            "\n",
            "epoch 136/200\n",
            "loss: 56.247234 +/- 16.386839\n",
            "val_loss: 56.530510 +/- 15.058534\n",
            "\n",
            "epoch 137/200\n",
            "loss: 55.604942 +/- 16.156162\n",
            "val_loss: 55.221848 +/- 15.570373\n",
            "\n",
            "epoch 138/200\n",
            "loss: 55.964359 +/- 16.039886\n",
            "val_loss: 55.369835 +/- 14.424007\n",
            "\n",
            "epoch 139/200\n",
            "loss: 55.064194 +/- 15.422642\n",
            "val_loss: 55.758476 +/- 15.447191\n",
            "\n",
            "epoch 140/200\n",
            "loss: 55.480709 +/- 15.845251\n",
            "val_loss: 55.654308 +/- 14.052220\n",
            "\n",
            "epoch 141/200\n",
            "loss: 55.096832 +/- 15.798100\n",
            "val_loss: 54.806763 +/- 14.612589\n",
            "\n",
            "epoch 142/200\n",
            "loss: 55.832962 +/- 16.351149\n",
            "val_loss: 55.302959 +/- 15.156766\n",
            "\n",
            "epoch 143/200\n",
            "loss: 55.576229 +/- 15.337812\n",
            "val_loss: 55.478168 +/- 14.570318\n",
            "\n",
            "epoch 144/200\n",
            "loss: 55.752571 +/- 16.022448\n",
            "val_loss: 55.589954 +/- 16.545252\n",
            "\n",
            "epoch 145/200\n",
            "loss: 55.461578 +/- 15.420046\n",
            "val_loss: 55.226620 +/- 15.112362\n",
            "\n",
            "epoch 146/200\n",
            "loss: 55.570805 +/- 15.492813\n",
            "val_loss: 55.080482 +/- 15.065241\n",
            "\n",
            "epoch 147/200\n",
            "loss: 55.232853 +/- 15.603108\n",
            "val_loss: 55.334869 +/- 15.897679\n",
            "\n",
            "epoch 148/200\n",
            "loss: 54.920277 +/- 15.542147\n",
            "val_loss: 55.786896 +/- 15.998386\n",
            "\n",
            "epoch 149/200\n",
            "loss: 54.930618 +/- 15.501019\n",
            "val_loss: 54.821030 +/- 15.145103\n",
            "\n",
            "epoch 150/200\n",
            "loss: 55.266281 +/- 15.169491\n",
            "val_loss: 55.973289 +/- 15.302811\n",
            "\n",
            "epoch 151/200\n",
            "loss: 55.029579 +/- 16.160793\n",
            "val_loss: 55.006870 +/- 15.302464\n",
            "\n",
            "epoch 152/200\n",
            "loss: 54.633385 +/- 15.155216\n",
            "val_loss: 54.806030 +/- 14.433907\n",
            "\n",
            "epoch 153/200\n",
            "loss: 54.905525 +/- 15.205529\n",
            "val_loss: 54.251751 +/- 14.532022\n",
            "\n",
            "epoch 154/200\n",
            "loss: 54.764652 +/- 15.502649\n",
            "val_loss: 54.178772 +/- 13.974499\n",
            "\n",
            "epoch 155/200\n",
            "loss: 54.976631 +/- 15.418702\n",
            "val_loss: 54.038132 +/- 14.909935\n",
            "\n",
            "epoch 156/200\n",
            "loss: 54.681446 +/- 15.322418\n",
            "val_loss: 54.140194 +/- 14.924486\n",
            "\n",
            "epoch 157/200\n",
            "loss: 54.458279 +/- 14.796978\n",
            "val_loss: 54.424618 +/- 13.570005\n",
            "\n",
            "epoch 158/200\n",
            "loss: 55.092342 +/- 15.969500\n",
            "val_loss: 54.595604 +/- 14.918263\n",
            "\n",
            "epoch 159/200\n",
            "loss: 55.451767 +/- 15.277112\n",
            "val_loss: 55.105019 +/- 15.450152\n",
            "\n",
            "epoch 160/200\n",
            "loss: 54.988411 +/- 15.514606\n",
            "val_loss: 56.071800 +/- 17.100874\n",
            "\n",
            "epoch 161/200\n",
            "loss: 55.301880 +/- 16.306829\n",
            "val_loss: 54.393330 +/- 13.947481\n",
            "\n",
            "epoch 162/200\n",
            "loss: 54.609241 +/- 15.211899\n",
            "val_loss: 53.495663 +/- 14.939342\n",
            "\n",
            "epoch 163/200\n",
            "loss: 54.956318 +/- 14.938544\n",
            "val_loss: 55.490379 +/- 15.293062\n",
            "\n",
            "epoch 164/200\n",
            "loss: 54.593849 +/- 16.128929\n",
            "val_loss: 53.453663 +/- 16.334637\n",
            "\n",
            "epoch 165/200\n",
            "loss: 55.096493 +/- 15.394433\n",
            "val_loss: 55.043159 +/- 14.890596\n",
            "\n",
            "epoch 166/200\n",
            "loss: 55.070469 +/- 15.659454\n",
            "val_loss: 54.159157 +/- 14.499039\n",
            "\n",
            "epoch 167/200\n",
            "loss: 55.124146 +/- 14.950121\n",
            "val_loss: 56.074730 +/- 16.465244\n",
            "\n",
            "epoch 168/200\n",
            "loss: 56.048317 +/- 14.864971\n",
            "val_loss: 54.286392 +/- 14.924520\n",
            "\n",
            "epoch 169/200\n",
            "loss: 54.785011 +/- 15.642563\n",
            "val_loss: 53.980389 +/- 13.710434\n",
            "\n",
            "epoch 170/200\n",
            "loss: 54.630493 +/- 14.357935\n",
            "val_loss: 55.250061 +/- 15.732254\n",
            "\n",
            "epoch 171/200\n",
            "loss: 54.808311 +/- 15.130175\n",
            "val_loss: 53.350372 +/- 13.899426\n",
            "\n",
            "epoch 172/200\n",
            "loss: 54.189289 +/- 15.234357\n",
            "val_loss: 53.705605 +/- 14.575891\n",
            "\n",
            "epoch 173/200\n",
            "loss: 54.179485 +/- 14.800540\n",
            "val_loss: 54.687130 +/- 15.407637\n",
            "\n",
            "epoch 174/200\n",
            "loss: 54.437881 +/- 14.954701\n",
            "val_loss: 52.809727 +/- 15.044712\n",
            "\n",
            "epoch 175/200\n",
            "loss: 53.713959 +/- 16.069258\n",
            "val_loss: 53.556404 +/- 14.193726\n",
            "\n",
            "epoch 176/200\n",
            "loss: 54.241417 +/- 15.542664\n",
            "val_loss: 54.624901 +/- 14.719681\n",
            "\n",
            "epoch 177/200\n",
            "loss: 54.271225 +/- 14.918431\n",
            "val_loss: 54.523472 +/- 14.596099\n",
            "\n",
            "epoch 178/200\n",
            "loss: 53.891411 +/- 14.985841\n",
            "val_loss: 53.882244 +/- 14.750202\n",
            "\n",
            "epoch 179/200\n",
            "loss: 53.863964 +/- 14.975267\n",
            "val_loss: 52.845772 +/- 13.884974\n",
            "\n",
            "epoch 180/200\n",
            "loss: 53.700981 +/- 14.815052\n",
            "val_loss: 53.360447 +/- 14.471515\n",
            "\n",
            "epoch 181/200\n",
            "loss: 53.403557 +/- 14.792914\n",
            "val_loss: 53.403614 +/- 12.837915\n",
            "\n",
            "epoch 182/200\n",
            "loss: 53.679108 +/- 14.769547\n",
            "val_loss: 52.431507 +/- 14.214213\n",
            "\n",
            "epoch 183/200\n",
            "loss: 53.324493 +/- 15.204360\n",
            "val_loss: 52.705807 +/- 14.346006\n",
            "\n",
            "epoch 184/200\n",
            "loss: 54.100945 +/- 15.281301\n",
            "val_loss: 53.360165 +/- 14.440909\n",
            "\n",
            "epoch 185/200\n",
            "loss: 53.919708 +/- 15.463455\n",
            "val_loss: 53.056404 +/- 15.336437\n",
            "\n",
            "epoch 186/200\n",
            "loss: 53.063980 +/- 14.712651\n",
            "val_loss: 53.341259 +/- 14.041572\n",
            "\n",
            "epoch 187/200\n",
            "loss: 53.183773 +/- 14.756988\n",
            "val_loss: 53.602982 +/- 14.919364\n",
            "\n",
            "epoch 188/200\n",
            "loss: 53.087475 +/- 14.312986\n",
            "val_loss: 52.926319 +/- 16.040079\n",
            "\n",
            "epoch 189/200\n",
            "loss: 53.686096 +/- 14.532587\n",
            "val_loss: 52.815418 +/- 12.766153\n",
            "\n",
            "epoch 190/200\n",
            "loss: 53.555019 +/- 15.203886\n",
            "val_loss: 52.863087 +/- 13.523507\n",
            "\n",
            "epoch 191/200\n",
            "loss: 54.174473 +/- 15.474851\n",
            "val_loss: 54.543171 +/- 15.517499\n",
            "\n",
            "epoch 192/200\n",
            "loss: 53.353481 +/- 14.906437\n",
            "val_loss: 52.696007 +/- 15.333189\n",
            "\n",
            "epoch 193/200\n",
            "loss: 53.775688 +/- 14.952495\n",
            "val_loss: 52.920776 +/- 14.067822\n",
            "\n",
            "epoch 194/200\n",
            "loss: 53.504730 +/- 14.776329\n",
            "val_loss: 51.689465 +/- 14.470269\n",
            "\n",
            "epoch 195/200\n",
            "loss: 53.753918 +/- 15.004147\n",
            "val_loss: 55.026985 +/- 16.066576\n",
            "\n",
            "epoch 196/200\n",
            "loss: 53.839584 +/- 14.634808\n",
            "val_loss: 51.371532 +/- 14.097654\n",
            "\n",
            "epoch 197/200\n",
            "loss: 53.244976 +/- 14.790339\n",
            "val_loss: 53.390972 +/- 14.268597\n",
            "\n",
            "epoch 198/200\n",
            "loss: 53.507893 +/- 15.560108\n",
            "val_loss: 52.261505 +/- 14.716663\n",
            "\n",
            "epoch 199/200\n",
            "loss: 52.960400 +/- 14.766066\n",
            "val_loss: 54.072750 +/- 15.676104\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYvvnxUtXBf"
      },
      "source": [
        "X_test= (torch.stack([x[0] for x in test_set])).to(device)\n",
        "\n",
        "y_test= (torch.stack([x[1] for x in test_set])).to(device)\n",
        "\n",
        "y_pred = model(X_test).cpu().data"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiwZOuUmunjI",
        "outputId": "a22731bd-814a-4111-ebdd-29ea6ccdf104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df_results = pd.DataFrame(\n",
        "    data=torch.cat((y_test, y_pred), axis=1),\n",
        "    columns={'y_test','y_pred'}\n",
        ")\n",
        "df_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tensor(398.)</td>\n",
              "      <td>tensor(425.2493)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tensor(10.)</td>\n",
              "      <td>tensor(112.7907)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tensor(172.)</td>\n",
              "      <td>tensor(217.5704)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tensor(263.)</td>\n",
              "      <td>tensor(221.9827)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tensor(312.)</td>\n",
              "      <td>tensor(272.6280)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3471</th>\n",
              "      <td>tensor(108.)</td>\n",
              "      <td>tensor(152.3598)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3472</th>\n",
              "      <td>tensor(206.)</td>\n",
              "      <td>tensor(90.1718)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3473</th>\n",
              "      <td>tensor(420.)</td>\n",
              "      <td>tensor(191.9801)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3474</th>\n",
              "      <td>tensor(38.)</td>\n",
              "      <td>tensor(8.7867)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3475</th>\n",
              "      <td>tensor(131.)</td>\n",
              "      <td>tensor(162.5440)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3476 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            y_test            y_pred\n",
              "0     tensor(398.)  tensor(425.2493)\n",
              "1      tensor(10.)  tensor(112.7907)\n",
              "2     tensor(172.)  tensor(217.5704)\n",
              "3     tensor(263.)  tensor(221.9827)\n",
              "4     tensor(312.)  tensor(272.6280)\n",
              "...            ...               ...\n",
              "3471  tensor(108.)  tensor(152.3598)\n",
              "3472  tensor(206.)   tensor(90.1718)\n",
              "3473  tensor(420.)  tensor(191.9801)\n",
              "3474   tensor(38.)    tensor(8.7867)\n",
              "3475  tensor(131.)  tensor(162.5440)\n",
              "\n",
              "[3476 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZsCdh0du1oY",
        "outputId": "d227930d-99d9-4edf-aaf1-056fedeb3c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "idx = torch.argsort(y_test, dim=0)\n",
        "\n",
        "plt.plot(y_test, y_test)\n",
        "plt.scatter(y_test[idx], y_pred[idx], color= 'red')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f81b1064dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD5CAYAAADItClGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgcVdX/P3d6ZhImiSQZFkPCzCRsguxE9j0EIUR4UWRxgIiRwCAaATVg9AXEKAEFg7KFzZAJogERfmOQJeILCCIT2fcAYwhrSNgTyDL390dV9VT31F7VXdXd5/M895mp6uqqW0vf773nnHtKaa0RBEEQBIC6tCsgCIIgZAcRBUEQBCGPiIIgCIKQR0RBEARByCOiIAiCIOQRURAEQRDy1PttoJS6HpgIvKO13tZcNxz4I9AG9ABHa63fU0opYBYwAVgJfFNr/R/zO5OAn5i7/bnWeo7fsTfYYAPd1tYW8pQEQRBqm0WLFr2rtd4wyneV3zwFpdS+wMfAjTZRuAhYobW+UCl1NjBMaz1NKTUB+C6GKOwGzNJa72aKSDcwFtDAImAXrfV7XsceO3as7u7ujnJegiAINYtSapHWemyU7/qaj7TW9wMrilYfAVg9/TnA/9jW36gN/gUMVUqNAL4M3KO1XmEKwT3AIVEqLAiCIJSOqD6FjbXWb5r/vwVsbP4/EnjNtt1Sc53b+n4opaYopbqVUt3Lli2LWD1BEAQhCrEdzdqwPyWWK0NrPVtrPVZrPXbDDSOZxARBEISIRBWFt02zEObfd8z1rwOb2rYbZa5zWy8IgiBkiKiicAcwyfx/EnC7bf2JymB34APTzHQXcLBSaphSahhwsLlOEARByBBBQlL/AOwPbKCUWgqcC1wI/EkpNRn4L3C0ufkCjMijxRghqScBaK1XKKUuAB41t/uZ1rrYeS0IgiCkjG9IappISKogCEJ4ShqSKgiCIJSP3l7NmX96nAVPvem/cQnwNR8JgiAI5eHBl97l+OseAeDuZ95mwnYjyl4HEQVBEISUWb22l/0vvo83PvgUgO1Grs9fvrNXKnURURAEQUiRriff4PSbHssv33banuzUMiy1+ogoCIIgpMAnn61l+/PvZl2vEexz0NYbc82Ju2DkFU0PEQVBEIQyM/fhHn56+zP55XvP3JfNNxqSXoVsiCgIgiCUifc+Wc1OF9yTXz5u1xZ++dXtUqxRf0QUBEEQysCl97zIrIUv5ZcfOvtANhm6Xoo1ckZEQRAEoYS88f4q9rzw7/nlqeO24IzxW6ZYI29EFARBEErEj297ipseWZJffuyn4xk2qDHFGvkjoiAIgpAwL739EeMvvT+/fMERX+SEPdrSq1AIRBQEQRASQmvNt+d0s/B5420C9XWKJ887mKbGymlqK6emgiAIGeY/S97jq1c8lF/+3Td2YuL2m6RYo2iIKAiCIMRgXa/miMsf5OnXPwRg5ND1uO8H+9NYX5n5RkUUBEEQIvKPF97hmzc8ml/unLwbe2+xQYo1io+IgiAIQkg+W7uOvS68j3c//gyAnVuGcsupe1JXl26KiiQQURAEQQjB7Y+/ztSbH88v33H6Xmw/amiKNUoWEQVBEIQAfPzZWrY9t+/V8odu+3muaN859QR2SSOiIAiC4MP1D77Kz7qezS///az9GLPh4BRrVDpEFARBEFxY/vFn7PLze/PLk/Zo5fwjtk2xRqVHREEQBMGBi+96nsvvezm//K9zxvH59QemWKPyIKIgCIJg47UVK9nnovvyyz84eEtOP3CLFGtUXkQUBEEQTH44/wnmL1qaX37ifw9m/aaGFGtUfkQUBEGoeZ5/60MO+c0D+eVffnU7jtu1JcUapYeIgiAINYvWmkk3PMr9Ly4DYGBDHY/99GDWa8ylXLP0EFEQBKEm6e5ZwVFXPZxfvur4nTlk2xEp1igbiCgIglBTrOvVHHbZAzz/1kcAtDY3ce+Z+9GQq8wEdkkjoiAIQs2w8Lm3mTynO79808m7sedmlZ3ALmlEFARBqHo+XbOO3X6xkA9WrQFgt9HD+cPJu1dFArukEVEQBKGquXXRUs6a/0R+ueu7e7PtyPVTrFG2EVEQBKEq+fDTNWx/3t355cN32ITLjtspxRpVBiIKgiBUHdfc/wozFjyXX/7HD/anbYNBKdaocoglCkqpM4BvAxp4CjgJGAHcDDQDi4ATtNarlVIDgBuBXYDlwDFa6544xxcEQbCz7KPP+NKMvgR2k/cezU8nbpNijSqPyDFYSqmRwPeAsVrrbYEccCwwE7hUa7058B4w2fzKZOA9c/2l5naCIAiJ8IsFzxUIwr9/PE4EIQJxzUf1wHpKqTVAE/AmcCDwDfPzOcB5wJXAEeb/ALcAv1NKKa21jlkHQRBqmCXLV7LvxX0J7KYd8gU69t8sxRpVNpFFQWv9ulLqV8ASYBVwN4a56H2t9Vpzs6XASPP/kcBr5nfXKqU+wDAxvWvfr1JqCjAFoKWlNnOPCIIQjO/f/Bh/efyN/PIT5x7M+uvVVgK7pIksCkqpYRi9/9HA+8B84JC4FdJazwZmA4wdO1ZGEYIg9OPZNz5kwmV9Cewu+tr2HP2lTVOsUfUQx3x0EPCq1noZgFLqz8BewFClVL05WhgFvG5u/zqwKbBUKVUPrI/hcBYEQQiE1ppvXPMID79iNB1DBtTz6E8OYmBD7SawS5o4orAE2F0p1YRhPhoHdAP3AUdhRCBNAm43t7/DXH7Y/Pzv4k8QBCEoj7yynGNm/yu/fM2JYxm/zcYp1qg6ieNTeEQpdQvwH2At8BiG2eevwM1KqZ+b664zv3IdMFcptRhYgRGpJAiC4Mnadb0cfOn9vPLuJwBsvtFg/jZ1H+olgV1JUFnurI8dO1Z3d3f7bygIQlVy1zNvccrcRfnlP52yB7uOHp5ijSoDpdQirfXYKN+VGc2CIGSOT9esY5cL7uGT1esA2GvzZjon74ZSksCu1IgoCIKQKf706Gv86NYn88t3Tt2HrUd8LsUa1RYiCoIgZIIPVq1hh/P7Eth9daeRXHLMjinWqDYRURAEIXWu+MdiLvrbC/nl+394AC3NTSnWqHYRURAEITXe/vBTdvvFwvzyKfuN4ZxDt06xRoKIgiAIqfCz//cs1//z1fzyo9MPYsMhA1KskQAiCoIglJlX3/2EA371j/zyTw7bmm/vMya9CgkFiCgIglAWtNZ89w+P0fXkm/l1T513MEMGSgK7LCGiIAhCyXn69Q+Y+NsH88uXHL0DX915VIo1EtwQURAEoWT09mqOmf0wj/a8B8DwQY08dPaBksAuw4goCIJQEh56+V2+cc0j+eXrvzmWA78gCeyyjmSUErLHvHnQ1gZ1dcbfefPSrpEQgjXretnnor/nBWHrEZ/j5V9MEEGoEEQUhGwxbx5MmQL//S9obfydMkWEoUK486k32WL6nby2YhUAt475iDsvPYFcfU4EvkKQLKlCtmhrM4SgmNZW6Okpd22EgKxavY4dfnY3q9f2ArD/VhtyQ8NLqFOmwMqVfRs2NcHs2dDenlJNa4M4WVJFFIRsUVdnjBCKUQp6e8tfH8GXmx5Zwo9veyq/fNf392Wrzw8RgU+ROKIg5iMhW7S0hFufBWrUB/L+ytW0nf3XvCAcPXYUPRceZggCwJIlzl90Wy9kAhEFIVvMmGGYGOw0NRnrs0iN+kAuW/gSO/7snvzyg9MO4KKjdijcqBIFXhBREDJGe7thc25tNUxGra3ZtkFPn15oMwdjefr08telDCOWtz74lLaz/8ol97wIwOkHbE7PhYcxaphDRtNKE3gBkHkKQhZpb8+uCBSTFROJNWKxBMoasUBi1/J/b3+aGx/u8xEs+slBNA/2SGBnHXf6dON6tLT0CUJbW+G6SrnfNYA4mgUhDllxppawHi8v+5hxv/6//PK5X9mGk/YaHW1nxeIFEpFUAsTRLAhpkRUTid+IJYJpSWvNKXO7CwTh6fO/HF0QwNvcVqMO+6whoiAIcUjSBxKnUfRy6kZwhj/x2vuMPmcBdz3zNgCzjt2RngsPY/CAmBZnN/Gy6lRjDvssIuYjQcgCcc0qXt+fPj2waam3V3PklQ/xxGvvA7DRkAE8MO0ABtQnlMDOzcyVy8G6dYHqKPgj5iNBSIJymC/cjhElism+r+nTYdIk5xFLQGf4Ay8tY8yPF+QFYc63duXf0w9KThDA3dzmJAj2OoppqXxorTNbdtllFy0IZaGzU+umJq0N44VRmpqM9eU4hlKF662iVPz6trY677u1VWut9Wdr1undf3Gvbp3WpVundemvfPtyvbYuZ3ye5Pnb697aapybdQyvOpbj3oStb8YBunXEdjf1ht+riCgIZcOn4Sz5McIeP8z2Ho3qHY+/nheD1mld+j+jt0+n8fVq+Mtxb6LUK8OIKAhCXML21JM+RtjGJ8rIwtbb/XhOp247u08MJv/+Ud1bisY3SC/b3vDncn3HtLYtx71xI01BikEcURCfgiBAeVIyuO1r+PA+n0LOtN/7RTH51bfYBg+Gw3buXG7cfF+++OxQtBljcu+1HVx77lEoJwcwRJ+IFyTqyb4NGL4FK6TXOveo9yYJP0RWJieWk6hqUo4iIwWhbKTlU2ho0LqxMfxxverr8tny075XYCr68cGn9e95J9Er9jL5FO8vSE88yr1x+o5SWnd0hDuXGhwppN7wexURBaGslMOhWHyM5ubojY5bfR0asl/v3V4gCK8P2cD5uMXCUNz4+l0jp8bYy+wT1DTkZ2Iqxq0xt0x1QRGfQraKiEKNUIHRHY5EOY9S2Mtt+1w6ZMMCMbh0r+O8G2yrsXU6hyANpNcIwSq5nKeAuYpimAba7brGGflU0PMpoiBULuXqiZX6hx31PEphnjD3efaXTy8QhBUDhwQThKh17ez033/xtQl63To7+0YIQersJU5xHdQVIBKpiQIwFLgFeB54DtgDGA7cA7xk/h1mbquAy4DFwJPAzn77F1GoAcphsy2H8EQ9j7h1c2igXrz2pgIxuHHHQ8M11G6EjZ4KKkAdHX0Nfi7X3+7vt2+nRt5r7kfQZ8up8a8Qc1KaojAH+Lb5f6MpEhcBZ5vrzgZmmv9PAO40xWF34BG//Yso1ADlCDcsh/D4mSs6OrzNMlF6nkUNVC/ok44+Py8Gm/3wdv1J40D3Hra9ODXGxUSZZ+FXkjBJud3HceOctw/ibHarVxwfUBlJRRSA9YFXMfMn2da/AIww/x8BvGD+fzVwnNN2bkVEoQZIssF2a1xLITxBHcZRe+Uhj9m9yRcKRgddT7zR9z0vwQpTpygzsr2KdR5+999r3151jvNshRW5csyZCEFaorAj8G/g98BjwLXAIOB92zbKWga6gL1tny0ExjrsdwrQDXS3tLSU9MIJGSCp4XjSM2K9ol2Chpb6lTDC52JCWavq9IRJv8mLwZ6nXqc/yzUUfi/ISKG4Tm4C67Y+rCiGaWTd7p/dYe2EX2fAfi7NzUbxEqqk7mUZSEsUxgJrgd3M5VnABXZRMNe/p0OIgr3ISKFGSMJx55c7p7jBbmx0P46XDdvLhNDcHK5BCdq7dGnY/z5ml4LRwYOtOxSec9SG2ul7XkLd2WmIYpRjBXEel8KJH8RP4XZtxKfgKgqfB3psy/sAfxXzUQ0St1FPQhT8nKBOjZabbTmqfdxq5IN+P+hchKJG6NNcvd7lO3PzYnDk8Rfrdai+Bqqjw7vBy+XcBSNKKGfU62VvVP0a2SjPSJTRo9e1sEdMSfSRqzA8AGxl/n8ecLFZ7I7mi8z/DytyNP/bb/8iChVAEtEzSfS8ojhB3SYyRbGP2xvNIJE4QWctF/Wkb9tm/4LRwROjt+vfQPk1eG7RQn7n7TayiXq9rGuWVCPrZA6yRNB+rDB1znjj70aaorCjaf9/EvgLMAxoNk1DLwH3AsPNbRVwOfAy8JSf6UiLKFQGcR3FSTmaozpBw8a4QzATQnFD5xV95La97RgfNq5XIAYdR5yte8HZDObX4Ln5DYKKXtDrFdSclkSD6yfEUSbZuU2gS3tUHIDURKHURUShAogb2ZNkZJDbDy7sRCY/n0LSJgSfXvu1Yw8vEISXh23i3ABbjlI/x/K4cc518PqeV94gv9FekAY4rl0+bCPvJyINDYWO5yTmKJRxjoOIgpAeQXv6YRvspCevhZ3I5BV9lDQu12BZ0/oFYnDuuCn+DV+QUmw2CzrxzM/Z7DUPI8j+/e6FlwAHMQe55VMqjj5qbnZOUujmh8nlgnUOyvGsm4goCOkRpPfjtU3Q3lPcnrnTRKasRI04NGgz9z2xQBDeHJxwyKe9IQrrKI5rNgnaaFvfC/J8xDF/FRPHcZ7kOzBiIKIgpItfg+3XQ/LrlQcVnjA91ShplEuF7fos+dxGBWLwu92/3lfnXC78XIggDXAUR3EcQQ3TYw4zEg3jUyj+bhjfSlTxkZGCiIJgEqSHFCV80CvaJ4hNu1wTjvxE06z/WROmFgjC+wMGFda3ocEQsiQmisUZKRTvx0scnM49jMgHETWnYxVPRosyJ6W4DBoUbFuvt9+VY1SstYiCkHGCNMpe2/iJil8+mrjD9jg/UrdGp7k5v5/n3vygQAxu2uHL3o1wEr1Z+yjJqY5hZmi79cL9zIb2+2a7HoEa6qQEPcy1tOpoPQthsrbar0mADkKg6+uBiIKQbYI86F4Nt5dgdHa6/4j9JpMFaVg6O/tPfGtoCDbHwKfB6W1q0sdfcFteDL7wkzv1yjGbezdMSsWbF1B87bx61vbspUH2V4zffYs6sSxJX1CYa+nkqE46miihUa2IgpBNvBqd4rh9r95+1AYkqHnJqb7Wcb1SWnidt09P99GRWxeMDu586o1g3/UaKbhdK6/G1e2ahNmPU4OpdXSh95tXkuTcgDAjhVLMWygmIWe0iIKQPbwa4o6O/g+/37uK3X58Xg1IUEe0V329Ggk3PBqaNapOj//W5Xkx2P/kq/XqXH1/x/qgQf2/HzRiK4iJw8/0ESUiKeh18DMJJukDCnKtgpjOyhWpJiMFEYWqwKnBdXu4rdGC22f2/dhHE07mjc5O98bNqyfvRBQ7vRsu29+72ZcKRgcPbbqdc8MTJFqqOMTWaUKadW/CiJ3VI/VLVx2kwYwaPBDWLBNlJGBvZN2c4UmOAIIiPgURhbIRJTIj6H7D9rD9GiS3/dpLXZ13oxX2nMLa6b1Ep0ioVuUa9HZTb86LwdHH/bIvgZ1TY+XXkHV0OH/uNeM4qGj7jRSKfRFRoo+s9X49eDdHdPH+vfZTxrkBiSHRRyIKJSdODLfTvoL4AsLk8HfqvUWNsPHLse/2gwtzPK+021oXbDt/2wMLRgdPbTTGe99+jmSvz3K5YPfQug5ejWlY4fG6tlG2D9pj9hqRen0exhyT1qghBiIKgjdBGrwgPxInX4BXcfpRe6VsDhKN5Fe8eoBuDU2Y2P8gjUJrq/6gsalADL77lR8E33+ckNMwxDW7BLm2URvQoMf38ynFrVcpIozKgIiC4E2UvDDFdHaGa6jtL2K3fsxuja/T7OKoDaOXuLntM+h5Bcxxc/XUiwsE4dWhI4Lt38sRH7R+QfHr/YY1uyTpHPY7fhBHuv3YcXr6SZ9XmRBRELxJYqQQp/dq9cZ9JnEVEDYk0t5guJFEfH9xA25rcN4eNaZADC44YHK4fVqCGbWexc7mqPZ8r/vt9pwkbbv3MgsFfS6S8BtUok9CaxEFwYckfAp+dm6/tM1RZ3+GSengFoFjEVXY3JzatgZqxv4nFQjC24OGhjtGUhPSvO550LQhft8Pc22j9qjdjh/meUiiNy8jhWwVEYUEiRt95NegWg1G2IYsrA8gSCMQpoccszHuGfr5AjG4ctevRbsGcQWh+Fp6NWZe+3B7ZoJEGSVte3c6ftBrlZTdX3wK2SoiChkiSAPtNQchSm8ubM/eMh8Fndhl+TkihtB+b+IPvBPYBT3/JAQBCiOvvMweXnb4pBvxpPEyK5Xq2BJ9lJ0iopAxvEwPUYrdBxCnV1jcMIQVn5Dn9fRGowvE4I/bHRT+3O35k5LIemoVPxORX6hwxs0ildpzLzciCkJ5SVIYtE7GfgzeE9r8Ui07pZUoKr2gjzn2F3kx2PasW/Sq+gCZRJ3ErbExfBrshoZA9XSdFRykxHWglqpXXarJl1WKiIJQXtwaca9G2atX6mUSSMreXjwT1+mVix7l4U23LRgd3L35rsHO12vegde5FadpLvaNeAmz1bAHDd0sPq7fvY874Syp503EwBURBaH0ONniixsHr8YmaiqCJATB2k+E/a1RdXr/k6/Oi8FBky/Xa1QI8Ys65wAKGz17Gutcru/6uwlRMUHrEDb7azleZlShEUBpIqIglJa4KQeKe+lhZs/GNVXFEJa/bbF7wejgkVFfDL+fOOdgn8zm9Pm4ccF70EHr4GU+8mucSxXTX6FzBdJEREEoLV5OyyTMB07fa2iIP5krSv4l0KvqG/XWZ8zPi0H7MRfo3jiiFCcUtrXVe+5HUBt+UB+DV+/br3Eu90jB2reYkfohoiCEI6wz0C+Nsp+ZI8ix7d9TSuv6+miNsL1eEb538/bjC0YHz27YZnxWV9cnUmHExjLHRA2F9ROPqPe9ubn/efi9Uc6rc+DmpymVTyHuMSowzDQMIgpJUOUPSZ4ovXk/04N90pjXewCc7OtKOZtB4hS7kzbgd94fMKhADM6YcEb/7YK+uN1evDKqBnEEe40UIPpz2tnZvwF3qmtY57w1witV9JHfMxh0X1XuuBZRiEsNPCR5ogzxgzhL/RrgIKGUSQmCRWdn//crO5TLdzuqQBCWrL9xsnUK0mB5PYNuPoU4z2nUVBf2Rj9K6pK4hPEvuAVHJCEsGUdEIS61FN3gl2q4mCC26CQTzcUtxY2DxzyAtwYPLxCDX+43qTx1csNrtOolDH7pPcI8B0FTZQTdR9IE/a1GmadRRY5rEYW41FJ0g1dPKUxEURYFwSp2X4bLNueOm1IgCO80hUxgF6Yk0bnwC/l1Gs3FTWCXlmPZfs7FIuc1ooo74z5gavRKQEQhLtUyUgjSU/TrQRWfs1ejn+TM5lKU4vcYg35l2CYFYnDNl/6n9PWwBMrv/njN2vWa+ayU+31ye4a9IqLsIcRe+yyl2TVI4+8nFnFKhZuPRRTikjWfQpgwQy8noNcL1b0aGDt+cw8ihn2Wu/SCPu2IaQWC8GHjeuU5vlvaieJEfUk2am730+n5sbYrrptThFTxM+U36zpqzzvsnJe4IwS3Y1UoIgpJkJXooyAC1dkZPGeO2zuL49hmvV6ak8Hy1MabFYjBrV88oPz1cLveXkn8kjquH1EnHcZ5hv3wC4P2Wg5arDpVoflYRKGaiBILHvThtxNUfKz62F+rGbdnVqayDqW/1j4zLwY7n96pP83FnP8QpZTS79LYGPy9124k3SgmYY71+h2EWW//3Ck1S1L1zRipigKQAx4Duszl0cAjwGLgj0CjuX6AubzY/LzNb981KQqlakCcHnCvXqCbOWPwYO/eVUbKP1u2Lxgd/H3M2HTrlISZrbm5f2jvgAHO4b72+SF+JN0oJiEybp0Wr+vj9rnfKCVr5uMESFsUzgRusonCn4Bjzf+vAjrM/08DrjL/Pxb4o9++a1IUStUDD9vr86tH2IyoVh3cGruETFGr63J6r1OuzYvBId+8TK8Nk8CulCXOOVomuwDzLlzfe+1GEo1i0Il4Ttt7BUXYR0GW891t314j2zD1l+ijWIIwClgIHAh0AQp4F6g3P98DuMv8/y5gD/P/enM75bX/mhSFUjkcg06gSvKFL8XFy3HpF3IZoFyx29cKRgfdI79QunOJUpx6+kHvXRiTXZQefpxGMcgz6+dUD2ribGgoTSqNKiNNUbgF2AXY3xSFDYDFts83BZ42/38aGGX77GVgA4d9TgG6ge6WlpZSXrfsEqTXFaYETUoXpBfqVoK80cup52evV8RzLU5RMemo86InsMtisa5dUJOd5Utwms1bip6wnx+s+HhBzVV+zvkq6dWXglREAZgIXGH+n5go2EtNjhSKiTtyCPqjiWO2CtJLDBLeGOHY0w75boEgPLTpdtHPI8slzJvogpjj4vSuiwXH7RhuJsugPocqjAoqF2mJwi+BpUAP8BawEpgn5iMbSdkpi/cTtHEI8+OJ6zj26uUPHuz+WcRopjcHNxeIwS6nz41X/0oozc3+vpww4hHVzBQ0Dbjb/uOOFCo4KqhcpB6Sao0UzP/nFzmaTzP//06Ro/lPfvutaFFwMsf4pSa2vhd3VrLXj8dt/0k4uOPEi4fY/hvH/Nw5vXWY0tFROv+NVZKe2GeFJHvd77BmprC4PSdhUmzE8SkEHeFUmeM4LFkThTHAv83Q0/nAAHP9QHN5sfn5GL/9VrQouP1447zusHjbsLOZvfLjxPUpWOdWwlDVF5s3LRCDr7ZfFH1/9tQTJapv4sXr+gZJZFdcovS4/dKeBG2Eo8zaL+fkuQondVEoValoUfD6MboRZ7js9+Px6kHac9kECTVNYY7CnqdeXyAIr31uw/j7ta5RKSOuikuc0YPX7OficM+wPoWgjW8lmHQqoY4lRkQhi3j9IN0opWPNL6FakHpDn9mlTDOaHx25dYEYfP+wM5Pbv/2taHFHSWFKXV20eR7W9Xdbb8dvBOQ3UdFrhJr1Xrg4qLWIQhaJYj4qVQ/Hr4Gwhw76NVb2mbIlHDH0QoEYtE7r0u8N9HBYRy32CVH2CU+lHj20toYXVi+fgj3HlZ9ox3XoBvV7pWXTl5GCiEIm6ewM9rrD4u/EdawVN26lmpAWtacboPxti90LxODifY4v2bH6Fb8kafbt4lxXay5Bko7uhgb/yXFOz1PSPeu0RxNpHz8DiChkFb/cQk6fJeVYs/8YytWgxixrVV2/0cGq+pDJ/5Iofr34sFE+bvsovt+lTkPu9jwl3bPOQk9doo9EFCqKpHsyZbLvl7LcuOOhBWJw446Hpl6nfqX4HsW57k75iYKITNQIL7/3KkR9b4ITYtNPHRGFSiOJnpT9R5p2YxmjrKpv7Dc6yEwCO3uxzGXFo7o4+wwrMtb2UY7l92z5jWrDdGKyMFKocUQUKg2vhjwIYd5nIbUAABhuSURBVG3RUZKwlaFcvM/xBWJw5xZ7pF6nUI15EnMcgoaS2kUprC8jrj09iiO6xm36aRNHFJTx/WwyduxY3d3dnXY1kqetDf773/7rlYK5c6G9Pdr3nWhoMPa7enXYWpaM9wcOZsepNxese3XmRFRK9YlEa6vxN+h9cEMp6O3tW543D6ZOheXL3b/jdk/r62Ht2sJ1zc0wa5b/M+VFXZ3RtPvV3c68eTB9OixZAi0tMGNGvDoIoVBKLdJaj43y3bqkKyMEYMYM4wdVjNbGD8mPJUuCH2vAgEwJwpmHnVkgCPM7f0RPpQkCGPcgriCAcc/b2oxGFIyGc/Bg7++sWQNDhhjCpJTxt7MTfv/7/uvefTd+Y9zSEm49GMfs6TFEo6dHBKGCkJFCWjiJgrXer/eVRGNUZl4fsiF7nXZDfnnkB+/wz6u+lWKNYtLaCkuXwrp1yeyvqQlmzzYaT7dnw47Xc5I08+bBlCmwcmXfOnt9hcwhI4VKxDI/FFNX19drBOP/tjajETjhhIoUhK9/Y2aBINxzbUdlC0J9vTHaS0oQwGhwrVFiLue//fDh3p9bz01dXeFIJArt7YYA2EchIghVi4wU0sKp92Vh9cLAfZsK4PkNWjlk8uX55T17nuCmPwYwj2Udq5cexrcTdL9z58Lxx/tv29gI11/v3DBLz77miTNSEFFIk3nzYNIk5x5nUo7MlPjSd25k2eC+3uzDV0xixEceztOs0Nzs7eS10Nq4fyedZNj4kzr2qlXBOwGtrYa9vhg3sXLbXqg6xHxUqbS3u9uFk3JkBrFPJ8i/Nt2WtmldeUE45om76Jk5sTIEAeDoo4Nds7o6w9wzYID/tkHvwWefhRsVugUchF0vCDbq065AzdPS4tz4t7Qk48gs00hQA6OndRWse+I3x7D+Z5+U5fiJMWdOsGumdXDRHj4cdtwRFi703u7jj4Ptz77ftra+sM8JE2DBAvf6F28vYaKCAzJScCNJR53XMZwagoYGY32SjswS8tet9ioQhO8/OI+emRMrTxDq6krjv1mxAhYvjreP4tFGQwN89JEhTJZAXXmlu1A5bT9lSmmea6GikZGCE8WOOusHBMn1rObNg299q/8cgsZGY10Qu3bKrFV1bP6jOwrWPf+rIxm4LiEbe7lxM+VZjmW3SVx+tLQEM904+RTsQQf2yWAffxz8GWltdd7einiS0YJgQ0YKTkyf3r/HaA8ZTIKpU50nlWVoopkXv995YoEgXHjnZfTMnFi5guCFFf7pNVnLjYYGw0zj992mJsOfsd56feuam/sihoong61YEez4SnlvL34GoQgRBSeiOOrCmpsqYCTgxMqGAbRN6+K88afm17180eEc++TdKdYqAlEc8DNmGI13lOM4fdf6rLXViEKbM6fwuVi1yn2/QQXK2i7KrGShNomaNKkcJbWEeOVIABY2cVpzc3lfGelQfrHfNwsS2N2z2a6p1idyCZtQzp7y2e11mH6ltdX4rlsm0iSeueJifwbdtndK4S1UPEiW1JAEecl9qVMFl/Nl8THL8vU+1y+9dW8G6hWpOL0RL0iD7vZchClez1CYdxC4vWXPS3Ss7zk9d5LBtOoQUQhD0AY/iZeKWI2QE1F7nGUupx3+owIxWLTJVqnXKXKpq9N6cIT3PFu96SReZlScKtvvrWvFHQuv5zfIMyvvOqgJRBTCUIofhVdj4SY4GX9N5pL1Ny4Qg/1Pvjr1OqVakrpfVs+/oyPYe6CLnx2vZ614f0m8j7nGX2tZqcQRhdpLcxElN7wfXnmMrH1bx2xuNv5m2NF8+ImX8OSILfPLC685hc1WvJ5ijTJCLuc/d6S52Uh97TZfwG8fuZzxHLpNLgsbFluc2iJMCgzJoVSxSJqLMJQiCsPKIumG/Ue8fHlmBeGZjUbTNq0rLwj7vdJNz8yJIggWQSYTHn200bh2djpHKvnto7fX+x0EYZ/T4og5pyiopiZjfTHlCM0WMkftiUKYH0UY2tvd02FXANtNvZnDTvptfvnfvzuBOfPPS69ClcqCBcZfe7rpMPg1+mHDYov3FyYNtuRQqk2i2p3KUVKLPoqz35TDRsOWB1p3KPAdTB9fGQ7wzBYn23xQB7VSwZ7Fzk53x7S9lPvdzEJmQBzNZSCokAQNNW1uDvbDLlHphX5hph82rpdafaqmODWYfg5lMLbp6Aj+PPrtM4nOTpT5N0ImiCMKtWc+sggzA9lyuAVJJhbUX3D00aklvLt96/0KEtj98P/m0DNzIkNWe8ygFfxxM0P6mYRaW42X61xxRfBjue2zudl4RpN4L7K8ca02iaom5SglNR+Fmd0ZdBjd2RmsV2j1DMvci11dl+s3Ovisrr7s9aiI0txsFKWM+Q1O2wwaFGz06PS8hR0ZBNmn9OIFE8R8FJKw8wqCxnYnMbmpRGX2l44sEIP52x6Yep08y7hx4eYGDBqU3FyC4sa+o8N9FnRQM00p/Fgyh0BwIY4o1N48BfCP9c7ljORk7e3+r8y0x3ZHTa1cQj5pGMgXz7ylYN0rM79CHdmqZwHNzfDuu8a1nz492MtsrPcbT52afMivNc/EmmNgn3cCErsvZI5U5ikopTZVSt2nlHpWKfWMUmqquX64UuoepdRL5t9h5nqllLpMKbVYKfWkUmrnqMeOjZ+Nd906w2dw0EFwwgnutv+PPy70K2Qs4+T5404uEITf/+l/6Zk5MduCAH1pntvbg4cKt7QY28+aZaSrDkIuZ0w088MSACdBAIndF6qKOI7mtcBZWuttgN2B7yiltgHOBhZqrbcAFprLAIcCW5hlCnBljGPHI0is98qVxusTvXr+y5cXOpwnTEiujjFY1jSUtmld3DD2CAAa166mZ+ZE9n/1PynXLCCWuJ52miHKfijVJx7Tp8OaAO90UMpo5MO+AtPteUgqdr8cb/wTBC+i2p2KC3A7MB54ARhhrhsBvGD+fzVwnG37/HZupaQhqW4ZI6MUy+GcAZ/Ct4+cXuA7ePzzW6Rep1DFcsCGvTcWKTjwC56BuM+kOI+FBCDtkFSlVBuwE/AIsLHW+k3zo7eAjc3/RwKv2b621FxXvK8pSqlupVT3smXLkqieM+3tht26s9MwI8TB6iWmONOzZ+gI2qZ1cc+WewCw1bIeemZOZIe3XkqtTpHYemvDPh/GL2CfNVwOE57TC3qKTYkWYXr+YdJKyIhCKBVR1cQqwGBgEfBVc/n9os/fM/92AXvb1i8Exnrtu2yT15LKWuoWulji8uWTflswOnh16Ih0estplOKedJiw4OJiRfEMHOh9PLeRTENDXxirFbUUpucfNMpNRhSCD6Q1UlBKNQC3AvO01n82V7+tlBphfj4CeMdc/zqwqe3ro8x16RM1T00xUbOsRuTJz29O27Qunt9oNADjX3yYnpkTaXv/TZ9vVjiDBvX9b3+nMRj38tRTw79us7XVuH8zZrgHFljvTL7iCmcH9Zo1xghHayNi6qqrwiWUC5qsURLVCSUkTvSRAq4DntNaX2L76A5gkvn/JAxfg7X+RDMKaXfgA91nZkof68XobtktM8aWZ/2Zwyf9Jr/86G+P55rbYib1yzpKwbhxRqNrUezsB9hrLxg+PPh+7TOR3RzVVpisFXYaxFRor6cdt+8GTdYoieqEUhJ1iAHsDWjgSeBxs0wAmjFMQy8B9wLDze0VcDnwMvAUPqYjrctgPnKb/JOkEzrhct/onQtMReeNOzn1OgUu48bF+77X28+ivjIzlys0u5RjoqKXU1reniYkADKjOQJOb76y7MXWjzJDwrAO1S9FxUeVlMAul4t/Pf3eOqZ1uMbaykqa1Gsx3Y7htBxnBrL4FAQfRBTC4uWMTCuk0aPM3/bAAjG4etcjU69T5kouF+7eWaGvQRp3twbXLibNzf1TYShljI4soQryuswwz7CkuBBciCMKtZnmwu2VhBljdV09W/7wLwXrXrr4CBp608muWlKcZgonjZWmorW171WXbs+C/bWYEyYYL89ZssT9NZlgTLa76qrC87BSYLil63B6DaYgxERexxkUK7a7AgTh8t2/XiAIs+64mJ6ZE6tTEBobSysITU1GAMHatcZx7Gml3Zyz1msxZ8ww8mAFSZu+YEH/87CigsQ5LFQI1S8KlhAoZaRMyLggfNS4Hm3Turh4v0n5da/OnMgRz/1firVKkOZmo9iXr7++NMcK8g4AvzDQMOGfXg1/Kd4NLggloLpFwf5yHPDvjW6zTenr5MFPxnew3Rnz88udN0+nZ+ZEQkbcZ5ujjzZCOy3LuhXmaReKMLjNRrfmHfi9bMYvDDRMD9+r4S/Vu8EFIWGqWxScenlepGTbfWfQMNqmddG582EADPnsE3pmTmTv/z6RSn1KivVi+2JmzQqfbqSpyRD9OI2t39vFwvTwvRp+eYuZUClE9VCXo8SOPspgJFFxmXTUeQWRRU9tNCb1OpW0OL3Y3iJMyKr9LXmljMQJGv5pn0NhhbVKVJCQEkj0kQsZdiq/PHwk406+Or+8/ZsvcseNZ6ZYowTp6DB6wUFeTGQnzEuKyhm1Y73sxy36yDJT2kel8uIdIUUk+siNGTOMhiZjnDduSoEgPHDV5OoRBDByA02Z0j//kJ9ZJ0xqCrtNv9QZQ60UKG4+CslFJFQR9WlXoKTccEPZk9R58eqwTThgyuz88omLuvjZvVelWKMSkMsZjfKcOYW9fqWM15q69ZznzYMPPwx+HMumX9xLt0JGoXy9dAk3FaqI6hWF004z3pyWATTwnSPOZsEX9s6ve+rSrzNk9ar0KlUqpkxx7jlr7e5khuBvTIP+CezceunlEoWWFmczpYSbChVI9mwrSTF7tv82ZeCpjTdj9LSuvCBc0vVremZOrE5B6OgwTEdRes5Be9XFUTtZ6KVLuKlQRVTvSMEtJ36Z6EXx9faZLBplzH1o/uR9/nnlSQxcF7A3XGkoZYwE6uqM4nT9vXrObr1tCzfHbRZ66VadvJzRglAhVO9IIe4rNmPwz9YdGDPt/+UF4Yb557Hod8dXryBAXwoIrZ0Fwa/n7NTbthzVXjH9Weml+zmjBaFCqF5RsJyNZWRNXY69T7mW9mONBmnrt1/h5YsO54BXSpDUrxLI5YJP1HKa3DV3bv9cRUG+J6GgghCZ6p6nMHAgfPZZchXyYMFWe3Ha/5yTX7517g/Y5Y3ny3LszKJUpqK/BKFWiDNPoXp9CgCrV5f8ECsbBrDD1JtZk2sA4ICXH+X6W86vrnxFUZHoG0GoOKrXfAThJkNFYO6Oh7LNmbfmBeHu607jhmoUhM5Ow4zT2ur8eXNzNuz6giDEpnpHCmEnQ4XgvYFD2GnqH/LLxzxxFzP/9tuSHCt1WlsN+/y8efDxx/0/b2oyktmBRN8IQhVQvT6FEuU9mrXnsVy6z/H55QevPIlRHy5L/DiZwAoDhf65fcAYIcyaJY2/IGQM8Sk4kfDkpTeHNLPHaXPyy9996GbOeqAz0WNkDiuKp63NOQX54MEiCIJQZVSvKAwfDsuXJ7Krn4zvyL/rAOA/l32D4atKY5oqOVZE0EEHeacBscxGkI1Zw4IglIXqdjTHZHHzqIKX35x3z1X0zJyYLUEozkTqhxURdO+9hgPZ6Y1nxU5ieZWkINQM1SsKMUYJGjj5yOkc9O2+DKbPXHIU3/xPVwIVS5BcDk49NXh6cKUMP4uVXrq93XgdZmen9+SvrMwaFgSh5FSnKMybF74HbfL4iC0ZPa2Le7bcA4BZd1xEz8yJDFrzaZI1TIZ164wU1aecAo2NhZ81NhoJ6qwwUqX6Ullb6aWt9w74pWjwmjVc6ncZCIJQVqoz+miDDUKPFHpRHHnCr3liky0B2Pij5Txw1WQae9eGP365aW01eu1uIaFukVhx314mbxwThEwSJ/qo+kRh3jw4/nj/7Wzc37YTJx5zQX75xj/+lH17Hgt33DTxSyfh9prLuGkoSiU2giDEQkJS7ZxySuBNV9fVs/ep1/HOEMPZusMbL3Lb3LOoI0WhbGoyGupPQ5ir/By+pUovLVFJglB1VJ9P4ZNPAm12x9b7suUP/5IXhL/ceCa3zz0zXUHI5QzTy7XX9vcRuKGUv8O3VI5iiUoShKqj+kYKPnzSMJAvnnlLfnn8iw8z+7YZ2chX1NtbaIu3+wjcZmdr7W+/L9VLYGbMcPYpSFSSIFQs1edT8Ig6mrPzRM4df2p++d5rTmXzFUujVq80WE7j4gY7q/b7efMk55EgZAzxKfiwYr3PsfP3bsovtz+2gBl3X5FijTywwkWh/1yBLPbK29tFBAShiii7T0EpdYhS6gWl1GKl1NmlPt4le7cXCMJDV3wzu4JgsXKl0fu2I28YEwShDJTVfKSUygEvAuOBpcCjwHFa62edto9jPlr6uQ3Zu+OG/OozHuhk6kM3R6p3KshbywRBiEglmY92BRZrrV8BUErdDBwBOIpCVD5uXK9AEB6bdRzDPv0oyUOUHongEQQhBcptPhoJvGZbXmquy6OUmqKU6lZKdS9bFu09BQ3r1nDYc/dzwV2X0zNzYrKCsM020NAQbNvm5v6hpU1NMG6cdxqOLPgKBEGoSTI3T0FrPVtrPVZrPXbDDTeMsgMGrFvL5XdcxAmP35lcxZQycgk98wzccINzdlEw1luvr3z3Xbj++v5+gHvvhblz+9Y3NxtFfAWCIKRMuX0KewDnaa2/bC6fA6C1/qXT9rHevCYIglCjxPEplHuk8CiwhVJqtFKqETgWuKPMdRAEQRBcKKujWWu9Vil1OnAXkAOu11o/U846CIIgCO6UffKa1noBsKDcxxUEQRD8yZyjWRAEQUgPEQVBEAQhj4iCIAiCkEdEQRAEQciT6dTZSqllgMuLBHzZAHg3wepUEnLutYmce23idO6tWusIs38zLgpxUEp1R528UenIucu51xpy7smdu5iPBEEQhDwiCoIgCEKeahaF2WlXIEXk3GsTOffaJNFzr1qfgiAIghCeah4pCIIgCCERURAEQRDyVKUoKKUOUUq9oJRarJQ6O+36JI1SalOl1H1KqWeVUs8opaaa64crpe5RSr1k/h1mrldKqcvM6/GkUmrndM8gHkqpnFLqMaVUl7k8Win1iHl+fzTTsqOUGmAuLzY/b0uz3kmglBqqlLpFKfW8Uuo5pdQeNXTfzzCf96eVUn9QSg2s1nuvlLpeKfWOUupp27rQ91kpNcnc/iWl1KQgx646UVBK5YDLgUOBbYDjlFLbpFurxFkLnKW13gbYHfiOeY5nAwu11lsAC81lMK7FFmaZAlxZ/ionylTgOdvyTOBSrfXmwHvAZHP9ZOA9c/2l5naVzizgb1rrLwA7YFyHqr/vSqmRwPeAsVrrbTFS7x9L9d773wOHFK0LdZ+VUsOBc4HdgF2Bcy0h8URrXVUF2AO4y7Z8DnBO2vUq8TnfDowHXgBGmOtGAC+Y/18NHGfbPr9dpRVglPmDOBDoAhTGbM764vuP8d6OPcz/683tVNrnEOPc1wdeLT6HGrnv1vvdh5v3sgv4cjXfe6ANeDrqfQaOA662rS/Yzq1U3UiBvofHYqm5rioxh8U7AY8AG2ut3zQ/egvY2Py/mq7Jb4AfAb3mcjPwvtZ6rblsP7f8eZuff2BuX6mMBpYBN5jms2uVUoOogfuutX4d+BWwBHgT414uonbuPYS/z5HufzWKQs2glBoM3Ap8X2v9of0zbXQNqireWCk1EXhHa70o7bqkRD2wM3Cl1non4BP6TAhAdd53ANPscQSGMG4CDKK/eaVmKOV9rkZReB3Y1LY8ylxXVSilGjAEYZ7W+s/m6reVUiPMz0cA75jrq+Wa7AUcrpTqAW7GMCHNAoYqpay3CNrPLX/e5ufrA8vLWeGEWQos1Vo/Yi7fgiES1X7fAQ4CXtVaL9NarwH+jPE81Mq9h/D3OdL9r0ZReBTYwoxKaMRwRt2Rcp0SRSmlgOuA57TWl9g+ugOwIgwmYfgarPUnmlEKuwMf2IahFYPW+hyt9SitdRvGff271roduA84ytys+Lyt63GUuX3F9qK11m8BrymltjJXjQOepcrvu8kSYHelVJP5/FvnXhP33iTsfb4LOFgpNcwcaR1srvMmbWdKiRw0E4AXgZeB6WnXpwTntzfG0PFJ4HGzTMCwmS4EXgLuBYab2yuMiKyXgacwIjhSP4+Y12B/oMv8fwzwb2AxMB8YYK4faC4vNj8fk3a9EzjvHYFu897/BRhWK/cdOB94HngamAsMqNZ7D/wBw3eyBmOEODnKfQa+ZV6DxcBJQY4taS4EQRCEPNVoPhIEQRAiIqIgCIIg5BFREARBEPKIKAiCIAh5RBQEQRCEPCIKgiAIQh4RBUEQBCHP/wdyDBKtRUHH3AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}